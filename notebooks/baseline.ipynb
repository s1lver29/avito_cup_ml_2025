{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb667370",
   "metadata": {},
   "source": [
    "ALS + GB\n",
    "Подобрать другие retrivials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced3b545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(60000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")  # noqa: E702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968271ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost.utils import get_gpu_device_count\n",
    "\n",
    "get_gpu_device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4860451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laptopml/avito_cup_ml_2025/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import implicit.gpu\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import implicit\n",
    "from scipy.sparse import csr_matrix\n",
    "from pathlib import Path\n",
    "from catboost import CatBoostRanker, Pool\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "implicit.gpu.HAS_CUDA\n",
    "# from tools.experiment_tracker import ExperimentTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb75a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path.cwd().parent / \"data\" / \"avito_ml_cup\"\n",
    "# Разделение на три части: тренировочную, валидационную и тестовую\n",
    "VALID_DAYS_RETRIEVER = 7\n",
    "VALID_DAYS_RERANKER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83e5295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_users = pl.read_parquet(f\"{DATA_DIR}/test_users.pq\")\n",
    "df_clickstream = pl.read_parquet(f\"{DATA_DIR}/clickstream.pq\")\n",
    "\n",
    "df_cat_features = pl.read_parquet(f\"{DATA_DIR}/cat_features.pq\", n_rows=100_000)\n",
    "df_text_features = pl.read_parquet(f\"{DATA_DIR}/text_features.pq\", n_rows=100_000)\n",
    "df_event = pl.read_parquet(f\"{DATA_DIR}/events.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03ce68da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (68_806_152, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>cookie</th><th>item</th><th>event</th><th>event_date</th><th>platform</th><th>surface</th><th>node</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>datetime[ns]</td><td>i64</td><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>19915558</td><td>17</td><td>2025-02-05 02:30:59</td><td>3</td><td>2</td><td>115659</td></tr><tr><td>0</td><td>2680232</td><td>17</td><td>2025-01-24 21:16:57</td><td>3</td><td>2</td><td>115829</td></tr><tr><td>1</td><td>4247649</td><td>17</td><td>2025-01-29 23:00:58</td><td>2</td><td>2</td><td>7</td></tr><tr><td>1</td><td>4247649</td><td>17</td><td>2025-02-17 14:55:17</td><td>2</td><td>2</td><td>7</td></tr><tr><td>1</td><td>2171135</td><td>17</td><td>2025-01-17 19:23:29</td><td>2</td><td>2</td><td>214458</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>149999</td><td>4999183</td><td>17</td><td>2025-01-20 12:23:47</td><td>2</td><td>2</td><td>71511</td></tr><tr><td>149999</td><td>25999164</td><td>17</td><td>2025-01-24 14:26:57</td><td>2</td><td>2</td><td>71514</td></tr><tr><td>149999</td><td>12138732</td><td>17</td><td>2025-02-12 13:11:42</td><td>2</td><td>2</td><td>51162</td></tr><tr><td>149999</td><td>28207042</td><td>17</td><td>2025-02-16 12:35:35</td><td>2</td><td>2</td><td>71511</td></tr><tr><td>149999</td><td>16282539</td><td>17</td><td>2025-02-10 13:07:17</td><td>2</td><td>2</td><td>71524</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (68_806_152, 7)\n",
       "┌────────┬──────────┬───────┬─────────────────────┬──────────┬─────────┬────────┐\n",
       "│ cookie ┆ item     ┆ event ┆ event_date          ┆ platform ┆ surface ┆ node   │\n",
       "│ ---    ┆ ---      ┆ ---   ┆ ---                 ┆ ---      ┆ ---     ┆ ---    │\n",
       "│ i64    ┆ i64      ┆ i64   ┆ datetime[ns]        ┆ i64      ┆ i64     ┆ u32    │\n",
       "╞════════╪══════════╪═══════╪═════════════════════╪══════════╪═════════╪════════╡\n",
       "│ 0      ┆ 19915558 ┆ 17    ┆ 2025-02-05 02:30:59 ┆ 3        ┆ 2       ┆ 115659 │\n",
       "│ 0      ┆ 2680232  ┆ 17    ┆ 2025-01-24 21:16:57 ┆ 3        ┆ 2       ┆ 115829 │\n",
       "│ 1      ┆ 4247649  ┆ 17    ┆ 2025-01-29 23:00:58 ┆ 2        ┆ 2       ┆ 7      │\n",
       "│ 1      ┆ 4247649  ┆ 17    ┆ 2025-02-17 14:55:17 ┆ 2        ┆ 2       ┆ 7      │\n",
       "│ 1      ┆ 2171135  ┆ 17    ┆ 2025-01-17 19:23:29 ┆ 2        ┆ 2       ┆ 214458 │\n",
       "│ …      ┆ …        ┆ …     ┆ …                   ┆ …        ┆ …       ┆ …      │\n",
       "│ 149999 ┆ 4999183  ┆ 17    ┆ 2025-01-20 12:23:47 ┆ 2        ┆ 2       ┆ 71511  │\n",
       "│ 149999 ┆ 25999164 ┆ 17    ┆ 2025-01-24 14:26:57 ┆ 2        ┆ 2       ┆ 71514  │\n",
       "│ 149999 ┆ 12138732 ┆ 17    ┆ 2025-02-12 13:11:42 ┆ 2        ┆ 2       ┆ 51162  │\n",
       "│ 149999 ┆ 28207042 ┆ 17    ┆ 2025-02-16 12:35:35 ┆ 2        ┆ 2       ┆ 71511  │\n",
       "│ 149999 ┆ 16282539 ┆ 17    ┆ 2025-02-10 13:07:17 ┆ 2        ┆ 2       ┆ 71524  │\n",
       "└────────┴──────────┴───────┴─────────────────────┴──────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clickstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "319ef528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=44)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clickstream[\"event_date\"].max() - df_clickstream[\"event_date\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191218bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63030/3723676151.py:23: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  df_eval = df_eval.filter(\n",
      "/tmp/ipykernel_63030/3723676151.py:30: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  df_eval = df_eval.filter(\n",
      "/tmp/ipykernel_63030/3723676151.py:32: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  ).filter(pl.col(\"node\").is_in(df_train_data[\"node\"].unique()))\n"
     ]
    }
   ],
   "source": [
    "# Определяем границы для разделения данных\n",
    "max_date = df_clickstream[\"event_date\"].max()\n",
    "retrivial_threshold = max_date - timedelta(days=VALID_DAYS_RETRIEVER + VALID_DAYS_RERANKER)\n",
    "reranker_threshold = max_date - timedelta(days=VALID_DAYS_RERANKER)\n",
    "\n",
    "# Разделяем данные\n",
    "df_train_retrivial = df_clickstream.filter(pl.col(\"event_date\") < retrivial_threshold)\n",
    "df_train_reranker = df_clickstream.filter(\n",
    "    pl.col(\"event_date\").is_between(retrivial_threshold, reranker_threshold)\n",
    ")\n",
    "df_valid = df_clickstream.filter(pl.col(\"event_date\") > reranker_threshold)\n",
    "\n",
    "\n",
    "# Создаем оценочные наборы для валидации и тестирования\n",
    "def prepare_eval_set(df_eval_raw, df_train_data):\n",
    "    # Выбираем только нужные колонки\n",
    "    df_eval = df_eval_raw[[\"cookie\", \"node\", \"event\"]]\n",
    "\n",
    "    # Исключаем пары cookie-node, которые уже встречались в тренировочных данных\n",
    "    df_eval = df_eval.join(df_train_data, on=[\"cookie\", \"node\"], how=\"anti\")\n",
    "\n",
    "    # Оставляем только контактные события\n",
    "    df_eval = df_eval.filter(\n",
    "        pl.col(\"event\").is_in(\n",
    "            df_event.filter(pl.col(\"is_contact\") == 1)[\"event\"].unique()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Оставляем только существующие в тренировочных данных cookies и nodes\n",
    "    df_eval = df_eval.filter(\n",
    "        pl.col(\"cookie\").is_in(df_train_data[\"cookie\"].unique())\n",
    "    ).filter(pl.col(\"node\").is_in(df_train_data[\"node\"].unique()))\n",
    "\n",
    "    # Оставляем только уникальные пары cookie-node\n",
    "    df_eval = df_eval.unique([\"cookie\", \"node\"])\n",
    "\n",
    "    return df_eval\n",
    "\n",
    "\n",
    "# Подготавливаем валидационный и тестовый наборы\n",
    "df_valid_eval_retrivial = prepare_eval_set(df_train_reranker, df_train_retrivial)\n",
    "df_valid_eval_reranker = prepare_eval_set(\n",
    "    df_valid, pl.concat([df_train_retrivial, df_train_reranker])\n",
    ")\n",
    "\n",
    "df_train_reranker = df_train_reranker.join(df_event, on=\"event\")\n",
    "\n",
    "df_valid = df_valid.join(df_event, on=\"event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f860c835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>cookie</th><th>node</th><th>event</th><th>is_contact</th></tr><tr><td>i64</td><td>u32</td><td>i64</td><td>i64</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 4)\n",
       "┌────────┬──────┬───────┬────────────┐\n",
       "│ cookie ┆ node ┆ event ┆ is_contact │\n",
       "│ ---    ┆ ---  ┆ ---   ┆ ---        │\n",
       "│ i64    ┆ u32  ┆ i64   ┆ i64        │\n",
       "╞════════╪══════╪═══════╪════════════╡\n",
       "└────────┴──────┴───────┴────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_eval_reranker.join(df_event, on=\"event\").sort(\"cookie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "492269b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочного набора retrivial: (57032043, 7)\n",
      "Размер валидационного набора reranker: (11774109, 8)\n",
      "Размер валидационного набора: (0, 8)\n",
      "Размер валидационного набора для оценки retrivial: (74771, 3)\n",
      "Размер валидационного набора для оценки reranker: (0, 3)\n"
     ]
    }
   ],
   "source": [
    "# Выводим информацию о размерах наборов данных\n",
    "print(f\"Размер тренировочного набора retrivial: {df_train_retrivial.shape}\")\n",
    "print(f\"Размер валидационного набора reranker: {df_train_reranker.shape}\")\n",
    "print(f\"Размер валидационного набора: {df_valid.shape}\")\n",
    "print(\n",
    "    f\"Размер валидационного набора для оценки retrivial: {df_valid_eval_retrivial.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"Размер валидационного набора для оценки reranker: {df_valid_eval_reranker.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9eddfc",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16cd850",
   "metadata": {},
   "source": [
    "## Train ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e72b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALSRetriever:\n",
    "    def __init__(self, **params_als):\n",
    "        self.model = implicit.als.AlternatingLeastSquares(**params_als)\n",
    "\n",
    "        self._user_id_to_index: dict[int, int] | None = None\n",
    "        self._item_id_to_index: dict[int, int] | None = None\n",
    "        self._index_to_item_id: dict[int, int] | None = None\n",
    "        self._sparse_matrix = None\n",
    "\n",
    "    def _create_mappings(self, user_ids, item_ids):\n",
    "        \"\"\"Создает маппинги между ID и индексами для пользователей и товаров\"\"\"\n",
    "        self._user_id_to_index = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "        self._item_id_to_index = {item_id: idx for idx, item_id in enumerate(item_ids)}\n",
    "        self._index_to_item_id = {v: k for k, v in self._item_id_to_index.items()}\n",
    "        self._index_to_user_id = {v: k for k, v in self._user_id_to_index.items()}\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        users,\n",
    "        nodes,\n",
    "        events=None,\n",
    "        event_weights=None,\n",
    "        contact_event_boost=10.0,\n",
    "        contact_events=None,\n",
    "        is_contact_col=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Обучает модель ALS\n",
    "\n",
    "        Args:\n",
    "            users (pl.Series): ID пользователей\n",
    "            nodes (pl.Series): ID элементов (товаров)\n",
    "            events (pl.Series, optional): Типы событий\n",
    "            event_weights (dict, optional): Словарь весов для разных типов событий\n",
    "            contact_event_boost (float): Множитель для контактных событий\n",
    "            contact_events (list, optional): Список ID контактных событий\n",
    "            is_contact_col (pl.Series, optional): Колонка с флагом контакта\n",
    "\n",
    "        Returns:\n",
    "            self: Возвращает self для возможности цепочки вызовов\n",
    "        \"\"\"\n",
    "        user_ids = users.unique().to_list()\n",
    "        item_ids = nodes.unique().to_list()\n",
    "\n",
    "        self._create_mappings(user_ids, item_ids)\n",
    "\n",
    "        rows = users.replace_strict(self._user_id_to_index).to_list()\n",
    "        cols = nodes.replace_strict(self._item_id_to_index).to_list()\n",
    "\n",
    "        # Определение весов взаимодействий\n",
    "        if events is not None and event_weights:\n",
    "            values = [event_weights.get(event, 1.0) for event in events.to_list()]\n",
    "\n",
    "            # Если указаны контактные события, увеличиваем их вес\n",
    "            if contact_events:\n",
    "                values = [\n",
    "                    val * contact_event_boost if events[i] in contact_events else val\n",
    "                    for i, val in enumerate(values)\n",
    "                ]\n",
    "        elif is_contact_col is not None:\n",
    "            # Если есть прямой признак контакта, используем его для весов\n",
    "            values = [\n",
    "                contact_event_boost if is_contact else 1.0\n",
    "                for is_contact in is_contact_col.to_list()\n",
    "            ]\n",
    "        else:\n",
    "            # По умолчанию все взаимодействия имеют вес 1\n",
    "            values = [1] * len(users)\n",
    "\n",
    "        # Создаем разреженную матрицу взаимодействий\n",
    "        self._sparse_matrix = csr_matrix(\n",
    "            (values, (rows, cols)), shape=(len(user_ids), len(item_ids))\n",
    "        )\n",
    "\n",
    "        # Обучаем модель\n",
    "        self.model.fit(self._sparse_matrix)\n",
    "\n",
    "    def recommend(self, user_ids, n=40, filter_already_liked_items=True):\n",
    "        \"\"\"\n",
    "        Генерирует рекомендации для указанных пользователей\n",
    "\n",
    "        Args:\n",
    "            user_ids (list): Список ID пользователей для рекомендаций\n",
    "            n (int): Количество рекомендаций для каждого пользователя\n",
    "            filter_already_liked_items (bool): Исключать ли уже взаимодействовавшие товары\n",
    "            recalculate_user (bool): Пересчитывать ли модель для пользователя\n",
    "\n",
    "        Returns:\n",
    "            pl.DataFrame: DataFrame с рекомендациями\n",
    "        \"\"\"\n",
    "        if not self._user_id_to_index:\n",
    "            raise ValueError(\"Сначала надо fit.\")\n",
    "        # Преобразуем ID пользователей в индексы\n",
    "        user_indices = []\n",
    "        valid_users = []\n",
    "\n",
    "        for user_id in user_ids:\n",
    "            if user_id in self._user_id_to_index:\n",
    "                user_indices.append(self._user_id_to_index[user_id])  # type: ignore\n",
    "                valid_users.append(user_id)\n",
    "\n",
    "        if not user_indices:\n",
    "            return pl.DataFrame({\"cookie\": [], \"node\": [], \"scores\": []})\n",
    "\n",
    "        # Получаем рекомендации\n",
    "        user_index_array = np.array(user_indices)\n",
    "        recommendations, scores = self.model.recommend(\n",
    "            user_index_array,\n",
    "            self._sparse_matrix[user_index_array],  # type: ignore\n",
    "            N=n,\n",
    "            filter_already_liked_items=filter_already_liked_items,\n",
    "        )\n",
    "\n",
    "        # Преобразуем индексы товаров обратно в ID\n",
    "        node_lists = [\n",
    "            [self._index_to_item_id[idx] for idx in rec] for rec in recommendations\n",
    "        ]  # type: ignore\n",
    "\n",
    "        # Создаем DataFrame с результатами\n",
    "        df_pred = pl.DataFrame(\n",
    "            {\"node\": node_lists, \"cookie\": valid_users, \"scores\": scores.tolist()}\n",
    "        )\n",
    "\n",
    "        # Разворачиваем списки\n",
    "        df_pred = df_pred.explode([\"node\", \"scores\"])\n",
    "\n",
    "        return df_pred\n",
    "\n",
    "    def save_model(self, path: str):\n",
    "        import pickle\n",
    "\n",
    "        model_data = {\n",
    "            \"model\": self.model,\n",
    "            \"user_id_to_index\": self._user_id_to_index,\n",
    "            \"item_id_to_index\": self._item_id_to_index,\n",
    "            \"index_to_item_id\": self._index_to_item_id,\n",
    "            \"index_to_user_id\": self._index_to_user_id,\n",
    "            \"sparse_matrix\": self._sparse_matrix,\n",
    "        }\n",
    "\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(model_data, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\"\n",
    "        Загружает модель из файла\n",
    "\n",
    "        Args:\n",
    "            path (str): Путь к файлу модели\n",
    "\n",
    "        Returns:\n",
    "            ALSRetrivier: Загруженная модель\n",
    "        \"\"\"\n",
    "        import pickle\n",
    "\n",
    "        with open(path, \"rb\") as f:\n",
    "            model_data = pickle.load(f)\n",
    "\n",
    "        retriever = cls()\n",
    "        retriever.model = model_data[\"model\"]\n",
    "        retriever._user_id_to_index = model_data[\"user_id_to_index\"]\n",
    "        retriever._item_id_to_index = model_data[\"item_id_to_index\"]\n",
    "        retriever._index_to_item_id = model_data[\"index_to_item_id\"]\n",
    "        retriever._index_to_user_id = model_data[\"index_to_user_id\"]\n",
    "        retriever._sparse_matrix = model_data[\"sparse_matrix\"]\n",
    "\n",
    "        return retriever\n",
    "\n",
    "\n",
    "def get_als_pred(\n",
    "    users,\n",
    "    nodes,\n",
    "    events,\n",
    "    user_to_pred,\n",
    "    event_weights=None,\n",
    "    generate_candidates: int = 40,\n",
    "):\n",
    "    user_ids = users.unique().to_list()\n",
    "    item_ids = nodes.unique().to_list()\n",
    "\n",
    "    user_id_to_index = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    item_id_to_index = {item_id: idx for idx, item_id in enumerate(item_ids)}\n",
    "    index_to_item_id = {v: k for k, v in item_id_to_index.items()}\n",
    "\n",
    "    rows = users.replace_strict(user_id_to_index).to_list()\n",
    "    cols = nodes.replace_strict(item_id_to_index).to_list()\n",
    "\n",
    "    # Используем веса событий или 1 по умолчанию\n",
    "    if event_weights is not None and events is not None:\n",
    "        values = [event_weights.get(event, 1.0) for event in events.to_list()]\n",
    "    else:\n",
    "        values = [1] * len(users)\n",
    "\n",
    "    sparse_matrix = csr_matrix(\n",
    "        (values, (rows, cols)), shape=(len(user_ids), len(item_ids))\n",
    "    )\n",
    "\n",
    "    model = implicit.als.AlternatingLeastSquares(iterations=10, factors=100)\n",
    "    model.fit(\n",
    "        sparse_matrix,\n",
    "    )\n",
    "\n",
    "    user4pred = np.array([user_id_to_index[i] for i in user_to_pred])\n",
    "\n",
    "    recommendations, scores = model.recommend(\n",
    "        user4pred,\n",
    "        sparse_matrix[user4pred],\n",
    "        N=generate_candidates,\n",
    "        filter_already_liked_items=True,\n",
    "    )\n",
    "\n",
    "    df_pred = pl.DataFrame(\n",
    "        {\n",
    "            \"node\": [\n",
    "                [index_to_item_id[i] for i in i] for i in recommendations.tolist()\n",
    "            ],\n",
    "            \"cookie\": list(user_to_pred),\n",
    "            \"scores\": scores.tolist(),\n",
    "        }\n",
    "    )\n",
    "    df_pred = df_pred.explode([\"node\", \"scores\"])\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "921be7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_retriever = ALSRetriever(iterations=50, factors=250, regularization=0.3, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a11d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = df_train_retrivial[\"cookie\"]\n",
    "nodes = df_train_retrivial[\"node\"]\n",
    "events = df_train_retrivial[\"event\"]\n",
    "eval_users = df_valid_eval_retrivial[\"cookie\"].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d139d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_weights(clickstream_df: pl.DataFrame):\n",
    "    event_count = {\n",
    "        row[0]: row[1] for row in clickstream_df.group_by(\"event\").len().rows()\n",
    "    }\n",
    "\n",
    "    return {event_id: 1.0 / np.log1p(count) for event_id, count in event_count.items()}\n",
    "\n",
    "\n",
    "inverse_freq_weights = create_event_weights(df_train_retrivial.select(\"event\"))\n",
    "\n",
    "# Можно также попробовать эту альтернативную стратегию взвешивания\n",
    "# df_pred_alt = get_als_pred(users, nodes, events, eval_users, inverse_freq_weights, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdfcbfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:38<00:00,  3.17s/it]\n"
     ]
    }
   ],
   "source": [
    "als_retriever.fit(\n",
    "    users, nodes, events, inverse_freq_weights, 100, list(inverse_freq_weights.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40e52c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_alt = als_retriever.recommend(eval_users, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43d62c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "del als_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab12f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularItemsRetriever:\n",
    "    \"\"\"\n",
    "    Класс для получения популярных товаров по различным критериям\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, clickstream_df=None, categories_df=None):\n",
    "        \"\"\"\n",
    "        Инициализирует ретривер популярных товаров\n",
    "\n",
    "        Args:\n",
    "            clickstream_df (pl.DataFrame, optional): DataFrame с данными кликстрима\n",
    "            categories_df (pl.DataFrame, optional): DataFrame с категориями товаров\n",
    "        \"\"\"\n",
    "        self.clickstream_df = clickstream_df\n",
    "        self.categories_df = categories_df\n",
    "\n",
    "        # Кэш для хранения результатов\n",
    "        self._cache = {}\n",
    "\n",
    "    def set_data(self, clickstream_df, categories_df=None):\n",
    "        \"\"\"\n",
    "        Устанавливает данные для работы\n",
    "\n",
    "        Args:\n",
    "            clickstream_df (pl.DataFrame): DataFrame с данными кликстрима\n",
    "            categories_df (pl.DataFrame, optional): DataFrame с категориями товаров\n",
    "\n",
    "        Returns:\n",
    "            self: Возвращает self для цепочки вызовов\n",
    "        \"\"\"\n",
    "        self.clickstream_df = clickstream_df\n",
    "        if categories_df is not None:\n",
    "            self.categories_df = categories_df\n",
    "\n",
    "        # Сбрасываем кэш при обновлении данных\n",
    "        self._cache = {}\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_popular_items(self, days=7, top_k=100, use_cache=True):\n",
    "        \"\"\"\n",
    "        Получает популярные товары за указанный период\n",
    "\n",
    "        Args:\n",
    "            days (int): Количество дней для анализа\n",
    "            top_k (int): Количество лучших товаров\n",
    "            use_cache (bool): Использовать кэш или пересчитать\n",
    "\n",
    "        Returns:\n",
    "            pl.DataFrame: Таблица с популярными товарами и количеством взаимодействий\n",
    "        \"\"\"\n",
    "        if self.clickstream_df is None:\n",
    "            raise ValueError(\"Не установлены данные кликстрима\")\n",
    "\n",
    "        cache_key = f\"popular_{days}_{top_k}\"\n",
    "        if use_cache and cache_key in self._cache:\n",
    "            return self._cache[cache_key]\n",
    "\n",
    "        # Определяем временное окно\n",
    "        cutoff_date = self.clickstream_df[\"event_date\"].max() - timedelta(days=days)\n",
    "        recent_data = self.clickstream_df.filter(pl.col(\"event_date\") > cutoff_date)\n",
    "\n",
    "        # Подсчитываем популярность каждого node\n",
    "        popular_nodes = (\n",
    "            recent_data.group_by(\"node\")\n",
    "            .agg(pl.count().alias(\"interaction_count\"))\n",
    "            .sort(\"interaction_count\", descending=True)\n",
    "            .head(top_k)\n",
    "        )\n",
    "\n",
    "        # Кэшируем результаты\n",
    "        if use_cache:\n",
    "            self._cache[cache_key] = popular_nodes\n",
    "\n",
    "        return popular_nodes\n",
    "\n",
    "    def get_popular_items_by_category(self, days=7, top_k=20, use_cache=True):\n",
    "        \"\"\"\n",
    "        Получает популярные товары по категориям за указанный период\n",
    "\n",
    "        Args:\n",
    "            days (int): Количество дней для анализа\n",
    "            top_k (int): Количество лучших товаров на категорию\n",
    "            use_cache (bool): Использовать кэш или пересчитать\n",
    "\n",
    "        Returns:\n",
    "            pl.DataFrame: Таблица с популярными товарами по категориям\n",
    "        \"\"\"\n",
    "        if self.clickstream_df is None or self.categories_df is None:\n",
    "            raise ValueError(\"Не установлены данные кликстрима или категорий товаров\")\n",
    "\n",
    "        cache_key = f\"popular_by_category_{days}_{top_k}\"\n",
    "        if use_cache and cache_key in self._cache:\n",
    "            return self._cache[cache_key]\n",
    "\n",
    "        # Определяем временное окно\n",
    "        cutoff_date = self.clickstream_df[\"event_date\"].max() - timedelta(days=days)\n",
    "        recent_data = self.clickstream_df.filter(pl.col(\"event_date\") > cutoff_date)\n",
    "\n",
    "        # Соединяем с категориями\n",
    "        recent_with_cat = recent_data.join(\n",
    "            self.categories_df[[\"node\", \"category\"]].unique(), on=\"node\", how=\"inner\"\n",
    "        )\n",
    "\n",
    "        # Подсчитываем популярность по категориям\n",
    "        popular_by_cat = (\n",
    "            recent_with_cat.group_by([\"category\", \"node\"])\n",
    "            .agg(pl.count().alias(\"interaction_count\"))\n",
    "            .sort([\"category\", \"interaction_count\"], descending=[False, True])\n",
    "        )\n",
    "\n",
    "        # Берем top_k для каждой категории\n",
    "        result = popular_by_cat.group_by(\"category\").head(top_k)\n",
    "\n",
    "        # Кэшируем результаты\n",
    "        if use_cache:\n",
    "            self._cache[cache_key] = result\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_trending_items(self, days_window=3, previous_days=7, top_k=100):\n",
    "        \"\"\"\n",
    "        Получает тренды - товары, растущие по популярности\n",
    "\n",
    "        Args:\n",
    "            days_window (int): Размер окна для текущей популярности (дни)\n",
    "            previous_days (int): Количество дней для сравнения с предыдущим периодом\n",
    "            top_k (int): Количество растущих товаров для возврата\n",
    "\n",
    "        Returns:\n",
    "            pl.DataFrame: Таблица с растущими товарами\n",
    "        \"\"\"\n",
    "        if self.clickstream_df is None:\n",
    "            raise ValueError(\"Не установлены данные кликстрима\")\n",
    "\n",
    "        max_date = self.clickstream_df[\"event_date\"].max()\n",
    "\n",
    "        # Данные для текущего окна\n",
    "        current_cutoff = max_date - timedelta(days=days_window)\n",
    "        current_data = self.clickstream_df.filter(pl.col(\"event_date\") > current_cutoff)\n",
    "\n",
    "        # Данные для предыдущего окна\n",
    "        prev_start = current_cutoff - timedelta(days=previous_days)\n",
    "        prev_data = self.clickstream_df.filter(\n",
    "            (pl.col(\"event_date\") <= current_cutoff)\n",
    "            & (pl.col(\"event_date\") > prev_start)\n",
    "        )\n",
    "\n",
    "        # Вычисляем популярность для текущего и предыдущего окна\n",
    "        current_pop = current_data.group_by(\"node\").agg(\n",
    "            pl.count().alias(\"current_count\")\n",
    "        )\n",
    "\n",
    "        prev_pop = prev_data.group_by(\"node\").agg(pl.count().alias(\"previous_count\"))\n",
    "\n",
    "        # Объединяем и вычисляем рост\n",
    "        trending = (\n",
    "            current_pop.join(prev_pop, on=\"node\", how=\"left\")\n",
    "            .with_columns(\n",
    "                [\n",
    "                    pl.col(\"previous_count\").fill_null(0),\n",
    "                    (pl.col(\"current_count\") - pl.col(\"previous_count\")).alias(\n",
    "                        \"growth\"\n",
    "                    ),\n",
    "                    (\n",
    "                        (pl.col(\"current_count\") - pl.col(\"previous_count\"))\n",
    "                        / (pl.col(\"previous_count\") + 1)\n",
    "                    ).alias(\"growth_rate\"),\n",
    "                ]\n",
    "            )\n",
    "            .sort(\"growth_rate\", descending=True)\n",
    "            .head(top_k)\n",
    "        )\n",
    "\n",
    "        return trending\n",
    "\n",
    "    def get_popular_for_user(self, user_id, days=30, top_k=50):\n",
    "        \"\"\"\n",
    "        Получает популярные товары для конкретного пользователя\n",
    "\n",
    "        Args:\n",
    "            user_id: ID пользователя (cookie)\n",
    "            days (int): Количество дней для анализа\n",
    "            top_k (int): Количество товаров для возврата\n",
    "\n",
    "        Returns:\n",
    "            pl.DataFrame: Таблица с товарами, популярными среди похожих пользователей\n",
    "        \"\"\"\n",
    "        if self.clickstream_df is None:\n",
    "            raise ValueError(\"Не установлены данные кликстрима\")\n",
    "\n",
    "        # Здесь может быть реализована логика определения похожих пользователей\n",
    "        # и получения популярных товаров среди них\n",
    "\n",
    "        # Простая реализация: товары из категорий, с которыми взаимодействовал пользователь\n",
    "        if self.categories_df is None:\n",
    "            return self.get_popular_items(days, top_k)\n",
    "\n",
    "        # Получаем категории товаров, с которыми взаимодействовал пользователь\n",
    "        user_categories = (\n",
    "            self.clickstream_df.filter(pl.col(\"cookie\") == user_id)\n",
    "            .join(\n",
    "                self.categories_df[[\"node\", \"category\"]].unique(),\n",
    "                on=\"node\",\n",
    "                how=\"inner\",\n",
    "            )[\"category\"]\n",
    "            .unique()\n",
    "        )\n",
    "\n",
    "        if len(user_categories) == 0:\n",
    "            return self.get_popular_items(days, top_k)\n",
    "\n",
    "        # Получаем популярные товары из категорий пользователя\n",
    "        cutoff_date = self.clickstream_df[\"event_date\"].max() - timedelta(days=days)\n",
    "        recent_data = self.clickstream_df.filter(pl.col(\"event_date\") > cutoff_date)\n",
    "\n",
    "        # Фильтруем по категориям пользователя\n",
    "        user_cat_items = (\n",
    "            recent_data.join(\n",
    "                self.categories_df.filter(pl.col(\"category\").is_in(user_categories))[\n",
    "                    [\"node\", \"category\"]\n",
    "                ].unique(),\n",
    "                on=\"node\",\n",
    "                how=\"inner\",\n",
    "            )\n",
    "            .group_by(\"node\")\n",
    "            .agg(pl.count().alias(\"interaction_count\"))\n",
    "            .sort(\"interaction_count\", descending=True)\n",
    "            .head(top_k)\n",
    "        )\n",
    "\n",
    "        return user_cat_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1897a4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63030/1626469783.py:66: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  .agg(pl.count().alias(\"interaction_count\"))\n",
      "/tmp/ipykernel_63030/1626469783.py:108: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  .agg(pl.count().alias(\"interaction_count\"))\n"
     ]
    }
   ],
   "source": [
    "popular_retriever = PopularItemsRetriever(df_train_retrivial, df_cat_features)\n",
    "\n",
    "# Получаем популярные товары за последнюю неделю и месяц\n",
    "popular_week = popular_retriever.get_popular_items(days=7, top_k=200)\n",
    "popular_month = popular_retriever.get_popular_items(days=30, top_k=300)\n",
    "popular_by_category = popular_retriever.get_popular_items_by_category(days=7, top_k=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01caae35",
   "metadata": {},
   "source": [
    "# Двустадийная система рекомендаций\n",
    "## Этап 1: ALS для первичного отбора релевантных товаров\n",
    "## Этап 2: CatBoost для ранжирования и уточнения результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58edc134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (11_774_109, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>cookie</th><th>item</th><th>event</th><th>event_date</th><th>platform</th><th>surface</th><th>node</th><th>is_contact</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>datetime[ns]</td><td>i64</td><td>i64</td><td>u32</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>4247649</td><td>17</td><td>2025-02-17 14:55:17</td><td>2</td><td>2</td><td>7</td><td>0</td></tr><tr><td>1</td><td>1874892</td><td>17</td><td>2025-02-22 07:30:38</td><td>2</td><td>2</td><td>243208</td><td>0</td></tr><tr><td>1</td><td>13385429</td><td>17</td><td>2025-02-16 14:33:07</td><td>2</td><td>2</td><td>151614</td><td>0</td></tr><tr><td>1</td><td>748003</td><td>17</td><td>2025-02-19 09:20:17</td><td>2</td><td>2</td><td>214364</td><td>0</td></tr><tr><td>1</td><td>6399591</td><td>17</td><td>2025-02-16 12:20:05</td><td>2</td><td>2</td><td>267694</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>149994</td><td>17225423</td><td>17</td><td>2025-02-18 17:11:24</td><td>2</td><td>2</td><td>199383</td><td>0</td></tr><tr><td>149994</td><td>17225423</td><td>17</td><td>2025-02-18 17:12:22</td><td>2</td><td>2</td><td>199383</td><td>0</td></tr><tr><td>149999</td><td>10685095</td><td>17</td><td>2025-02-19 13:06:25</td><td>2</td><td>2</td><td>136796</td><td>0</td></tr><tr><td>149999</td><td>9268894</td><td>17</td><td>2025-02-16 07:37:09</td><td>2</td><td>2</td><td>109807</td><td>0</td></tr><tr><td>149999</td><td>28207042</td><td>17</td><td>2025-02-16 12:35:35</td><td>2</td><td>2</td><td>71511</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (11_774_109, 8)\n",
       "┌────────┬──────────┬───────┬─────────────────────┬──────────┬─────────┬────────┬────────────┐\n",
       "│ cookie ┆ item     ┆ event ┆ event_date          ┆ platform ┆ surface ┆ node   ┆ is_contact │\n",
       "│ ---    ┆ ---      ┆ ---   ┆ ---                 ┆ ---      ┆ ---     ┆ ---    ┆ ---        │\n",
       "│ i64    ┆ i64      ┆ i64   ┆ datetime[ns]        ┆ i64      ┆ i64     ┆ u32    ┆ i64        │\n",
       "╞════════╪══════════╪═══════╪═════════════════════╪══════════╪═════════╪════════╪════════════╡\n",
       "│ 1      ┆ 4247649  ┆ 17    ┆ 2025-02-17 14:55:17 ┆ 2        ┆ 2       ┆ 7      ┆ 0          │\n",
       "│ 1      ┆ 1874892  ┆ 17    ┆ 2025-02-22 07:30:38 ┆ 2        ┆ 2       ┆ 243208 ┆ 0          │\n",
       "│ 1      ┆ 13385429 ┆ 17    ┆ 2025-02-16 14:33:07 ┆ 2        ┆ 2       ┆ 151614 ┆ 0          │\n",
       "│ 1      ┆ 748003   ┆ 17    ┆ 2025-02-19 09:20:17 ┆ 2        ┆ 2       ┆ 214364 ┆ 0          │\n",
       "│ 1      ┆ 6399591  ┆ 17    ┆ 2025-02-16 12:20:05 ┆ 2        ┆ 2       ┆ 267694 ┆ 0          │\n",
       "│ …      ┆ …        ┆ …     ┆ …                   ┆ …        ┆ …       ┆ …      ┆ …          │\n",
       "│ 149994 ┆ 17225423 ┆ 17    ┆ 2025-02-18 17:11:24 ┆ 2        ┆ 2       ┆ 199383 ┆ 0          │\n",
       "│ 149994 ┆ 17225423 ┆ 17    ┆ 2025-02-18 17:12:22 ┆ 2        ┆ 2       ┆ 199383 ┆ 0          │\n",
       "│ 149999 ┆ 10685095 ┆ 17    ┆ 2025-02-19 13:06:25 ┆ 2        ┆ 2       ┆ 136796 ┆ 0          │\n",
       "│ 149999 ┆ 9268894  ┆ 17    ┆ 2025-02-16 07:37:09 ┆ 2        ┆ 2       ┆ 109807 ┆ 0          │\n",
       "│ 149999 ┆ 28207042 ┆ 17    ┆ 2025-02-16 12:35:35 ┆ 2        ┆ 2       ┆ 71511  ┆ 0          │\n",
       "└────────┴──────────┴───────┴─────────────────────┴──────────┴─────────┴────────┴────────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2d868b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates_train = df_pred_alt.join(\n",
    "    df_train_reranker[\"node\", \"cookie\", \"is_contact\"]\n",
    "    .sort(\"is_contact\", descending=True)\n",
    "    .unique([\"cookie\", \"node\"]),\n",
    "    on=[\"cookie\", \"node\"],\n",
    "    how=\"left\",\n",
    ").fill_null(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b29e5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных для CatBoost\n",
    "def prepare_features_for_boosting(\n",
    "    df_retrieval,\n",
    "    df_clickstream,\n",
    "    df_cat_features,\n",
    "    df_popular_week,\n",
    "    df_popular_month,\n",
    "    df_popular_by_cat,\n",
    "):\n",
    "    \"\"\"Подготавливает признаки для обучения бустинга на основе результатов ALS\"\"\"\n",
    "    # Добавляем информацию о рейтинге ALS\n",
    "    features = df_retrieval.rename({\"scores\": \"als_score\"})\n",
    "\n",
    "    # Добавляем признак о популярности группы товаров\n",
    "    features = features.join(\n",
    "        df_popular_week.select([\"node\", \"interaction_count\"]).rename(\n",
    "            {\"interaction_count\": \"popular_week_count\"}\n",
    "        ),\n",
    "        on=\"node\",\n",
    "        how=\"left\",\n",
    "    ).with_columns(pl.col(\"popular_week_count\").fill_null(-1))\n",
    "\n",
    "    # # Добавляем признак о популярности группы товаров\n",
    "    features = features.join(\n",
    "        df_popular_month.select([\"node\", \"interaction_count\"]).rename(\n",
    "            {\"interaction_count\": \"popular_month_count\"}\n",
    "        ),\n",
    "        on=\"node\",\n",
    "        how=\"left\",\n",
    "    ).with_columns(pl.col(\"popular_month_count\").fill_null(-1))\n",
    "\n",
    "    # Добавляем количество взаимодействий пользователя\n",
    "    user_activity = df_clickstream.group_by(\"cookie\").agg(\n",
    "        pl.len().alias(\"user_activity_count\")\n",
    "    )\n",
    "    features = features.join(user_activity, on=\"cookie\", how=\"left\")\n",
    "\n",
    "    # Добавляем информацию о категории товара\n",
    "    features = features.join(\n",
    "        df_cat_features.select([\"node\", \"category\"]).unique(),\n",
    "        on=\"node\",\n",
    "        how=\"left\",\n",
    "    ).fill_null(-1)\n",
    "\n",
    "    features = features.join(\n",
    "        df_popular_by_cat, on=[\"node\", \"category\"], how=\"left\"\n",
    "    ).fill_null(-1)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "# Подготовка данных для обучения CatBoost\n",
    "def prepare_catboost_data(features_df, df_eval, max_items_per_user=100):\n",
    "    \"\"\"Подготавливает данные для обучения CatBoost с позитивными и негативными примерами\"\"\"\n",
    "    # Фильтруем топ-N предсказаний ALS для каждого пользователя\n",
    "    top_predictions = features_df.group_by(\"cookie\")\n",
    "\n",
    "    # Помечаем позитивные примеры (те, которые есть в df_eval)\n",
    "    labeled_data = top_predictions.join(\n",
    "        df_eval[[\"cookie\", \"node\"]], on=[\"cookie\", \"node\"], how=\"left\"\n",
    "    )\n",
    "\n",
    "    return labeled_data\n",
    "\n",
    "\n",
    "# Готовим данные для CatBoost\n",
    "train_data_for_boosting = prepare_features_for_boosting(\n",
    "    df_candidates_train,\n",
    "    df_train_retrivial,\n",
    "    df_cat_features,\n",
    "    popular_week,\n",
    "    popular_month,\n",
    "    popular_by_category,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97a6d238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7_027_400, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>node</th><th>cookie</th><th>als_score</th><th>is_contact</th><th>popular_week_count</th><th>popular_month_count</th><th>user_activity_count</th><th>category</th><th>interaction_count</th></tr><tr><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>115834</td><td>0</td><td>0.955596</td><td>0</td><td>8004</td><td>37031</td><td>258</td><td>19</td><td>8004</td></tr><tr><td>115669</td><td>0</td><td>0.921513</td><td>0</td><td>-1</td><td>-1</td><td>258</td><td>19</td><td>-1</td></tr><tr><td>1907</td><td>0</td><td>0.920921</td><td>0</td><td>18366</td><td>55094</td><td>258</td><td>25</td><td>18366</td></tr><tr><td>115810</td><td>0</td><td>0.9163</td><td>0</td><td>-1</td><td>-1</td><td>258</td><td>19</td><td>4729</td></tr><tr><td>1923</td><td>0</td><td>0.890081</td><td>0</td><td>23326</td><td>89071</td><td>258</td><td>61</td><td>23326</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>214290</td><td>149997</td><td>0.389333</td><td>0</td><td>12345</td><td>52178</td><td>284</td><td>37</td><td>12345</td></tr><tr><td>132695</td><td>149997</td><td>0.388594</td><td>0</td><td>-1</td><td>-1</td><td>284</td><td>24</td><td>-1</td></tr><tr><td>134516</td><td>149997</td><td>0.388434</td><td>0</td><td>-1</td><td>-1</td><td>284</td><td>24</td><td>-1</td></tr><tr><td>170706</td><td>149997</td><td>0.388252</td><td>0</td><td>-1</td><td>-1</td><td>284</td><td>-1</td><td>-1</td></tr><tr><td>229479</td><td>149997</td><td>0.387112</td><td>0</td><td>-1</td><td>-1</td><td>284</td><td>51</td><td>-1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7_027_400, 9)\n",
       "┌────────┬────────┬───────────┬────────────┬───┬─────────────┬─────────────┬──────────┬────────────┐\n",
       "│ node   ┆ cookie ┆ als_score ┆ is_contact ┆ … ┆ popular_mon ┆ user_activi ┆ category ┆ interactio │\n",
       "│ ---    ┆ ---    ┆ ---       ┆ ---        ┆   ┆ th_count    ┆ ty_count    ┆ ---      ┆ n_count    │\n",
       "│ i64    ┆ i64    ┆ f64       ┆ i64        ┆   ┆ ---         ┆ ---         ┆ i64      ┆ ---        │\n",
       "│        ┆        ┆           ┆            ┆   ┆ i64         ┆ i64         ┆          ┆ i64        │\n",
       "╞════════╪════════╪═══════════╪════════════╪═══╪═════════════╪═════════════╪══════════╪════════════╡\n",
       "│ 115834 ┆ 0      ┆ 0.955596  ┆ 0          ┆ … ┆ 37031       ┆ 258         ┆ 19       ┆ 8004       │\n",
       "│ 115669 ┆ 0      ┆ 0.921513  ┆ 0          ┆ … ┆ -1          ┆ 258         ┆ 19       ┆ -1         │\n",
       "│ 1907   ┆ 0      ┆ 0.920921  ┆ 0          ┆ … ┆ 55094       ┆ 258         ┆ 25       ┆ 18366      │\n",
       "│ 115810 ┆ 0      ┆ 0.9163    ┆ 0          ┆ … ┆ -1          ┆ 258         ┆ 19       ┆ 4729       │\n",
       "│ 1923   ┆ 0      ┆ 0.890081  ┆ 0          ┆ … ┆ 89071       ┆ 258         ┆ 61       ┆ 23326      │\n",
       "│ …      ┆ …      ┆ …         ┆ …          ┆ … ┆ …           ┆ …           ┆ …        ┆ …          │\n",
       "│ 214290 ┆ 149997 ┆ 0.389333  ┆ 0          ┆ … ┆ 52178       ┆ 284         ┆ 37       ┆ 12345      │\n",
       "│ 132695 ┆ 149997 ┆ 0.388594  ┆ 0          ┆ … ┆ -1          ┆ 284         ┆ 24       ┆ -1         │\n",
       "│ 134516 ┆ 149997 ┆ 0.388434  ┆ 0          ┆ … ┆ -1          ┆ 284         ┆ 24       ┆ -1         │\n",
       "│ 170706 ┆ 149997 ┆ 0.388252  ┆ 0          ┆ … ┆ -1          ┆ 284         ┆ -1       ┆ -1         │\n",
       "│ 229479 ┆ 149997 ┆ 0.387112  ┆ 0          ┆ … ┆ -1          ┆ 284         ┆ 51       ┆ -1         │\n",
       "└────────┴────────┴───────────┴────────────┴───┴─────────────┴─────────────┴──────────┴────────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_for_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31c0bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"node\",\n",
    "    \"als_score\",\n",
    "    \"popular_week_count\",\n",
    "    \"popular_month_count\",\n",
    "    \"user_activity_count\",\n",
    "    \"category\",\n",
    "    \"interaction_count\"\n",
    "]\n",
    "\n",
    "target_col = \"is_contact\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a1240a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRanker(\n",
    "    boosting_type=\"Plain\",\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    objective=\"PairLogitPairwise:max_pairs=100000\",\n",
    "    random_seed=42,\n",
    "    verbose=50,\n",
    "    nan_mode=\"Min\",\n",
    "    task_type=\"GPU\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44f6e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6831864\ttotal: 450ms\tremaining: 3m 44s\n",
      "50:\tlearn: 0.5598720\ttotal: 15.1s\tremaining: 2m 13s\n",
      "100:\tlearn: 0.5476751\ttotal: 29.3s\tremaining: 1m 55s\n",
      "150:\tlearn: 0.5410434\ttotal: 42.8s\tremaining: 1m 38s\n",
      "200:\tlearn: 0.5361645\ttotal: 56.3s\tremaining: 1m 23s\n",
      "250:\tlearn: 0.5316450\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "300:\tlearn: 0.5275545\ttotal: 1m 23s\tremaining: 55.3s\n",
      "350:\tlearn: 0.5240518\ttotal: 1m 38s\tremaining: 41.7s\n",
      "400:\tlearn: 0.5205834\ttotal: 1m 51s\tremaining: 27.6s\n",
      "450:\tlearn: 0.5173379\ttotal: 2m 5s\tremaining: 13.6s\n",
      "499:\tlearn: 0.5144240\ttotal: 2m 19s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x7fa8f01073d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data_for_boosting.select(feature_cols).to_pandas(),\n",
    "    train_data_for_boosting.select(target_col).to_pandas(),\n",
    "    group_id=train_data_for_boosting[\"cookie\"].to_list(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbfad59",
   "metadata": {},
   "source": [
    "# Оценка моделей\n",
    "## Метрика Recall@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89f6289f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты ALS модели на валидационном наборе:\n",
      "ALS_recall@10: 0.0651\n",
      "ALS_recall@20: 0.1027\n",
      "ALS_recall@30: 0.1302\n",
      "ALS_recall@40: 0.1522\n"
     ]
    }
   ],
   "source": [
    "def recall_at(df_true, df_pred, k=40):\n",
    "    \"\"\"Вычисляет метрику Recall@K для рекомендаций\"\"\"\n",
    "    return (\n",
    "        df_true[[\"node\", \"cookie\"]]\n",
    "        .join(\n",
    "            df_pred.group_by(\"cookie\")\n",
    "            .head(k)\n",
    "            .with_columns(value=1)[[\"node\", \"cookie\", \"value\"]],\n",
    "            how=\"left\",\n",
    "            on=[\"cookie\", \"node\"],\n",
    "        )\n",
    "        .select([pl.col(\"value\").fill_null(0), \"cookie\"])\n",
    "        .group_by(\"cookie\")\n",
    "        .agg([pl.col(\"value\").sum() / pl.col(\"value\").count()])[\"value\"]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_models(\n",
    "    df_true, df_als_pred, df_catboost_pred=None, k_values=[10, 20, 30, 40]\n",
    "):\n",
    "    \"\"\"Сравнивает модели по метрике Recall@K для разных значений K\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for k in k_values:\n",
    "        results[f\"ALS_recall@{k}\"] = recall_at(df_true, df_als_pred, k=k)\n",
    "        if df_catboost_pred is not None:\n",
    "            results[f\"CatBoost_recall@{k}\"] = recall_at(df_true, df_catboost_pred, k=k)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Оцениваем модель ALS на валидационном наборе\n",
    "als_results = evaluate_models(\n",
    "    df_valid_eval_retrivial, df_pred_alt, k_values=[10, 20, 30, 40]\n",
    ")\n",
    "print(\"\\nРезультаты ALS модели на валидационном наборе:\")\n",
    "for metric, value in als_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2481264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall_at(df_eval, df_pred_alt, k=40)\n",
    "\n",
    "# Можно сохранить обученные модели и результаты для дальнейшего использования\n",
    "\n",
    "# Пример организации модулей для ClearML:\n",
    "\"\"\"\n",
    "from tools.experiment_tracker import ExperimentTracker\n",
    "\n",
    "# Инициализация трекера экспериментов\n",
    "tracker = ExperimentTracker(project_name=\"avito_cup_ml_2025\", task_name=\"als_catboost_pipeline\")\n",
    "\n",
    "# Логирование параметров\n",
    "tracker.log_params({\n",
    "    'als_factors': 60,\n",
    "    'als_iterations': 10,\n",
    "    'catboost_iterations': 500,\n",
    "    'catboost_learning_rate': 0.05,\n",
    "    'catboost_depth': 6\n",
    "})\n",
    "\n",
    "# Логирование метрик\n",
    "tracker.log_metrics(als_results)\n",
    "\n",
    "# Сохранение моделей\n",
    "tracker.save_model(model, 'catboost_ranker')\n",
    "\n",
    "# Завершение эксперимента\n",
    "tracker.close()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df_train_reranker = df_train_reranker.drop(\"is_contact\")\n",
    "df_train_retriever_and_reranker = pl.concat([df_train_retrivial, df_train_reranker])\n",
    "\n",
    "# Применение двустадийной модели на тестовом наборе\n",
    "# Сначала получаем рекомендации от ALS\n",
    "\n",
    "# test_users = df_valid_eval_reranker[\"cookie\"].unique().to_list()\n",
    "test_users = df_test_users[\"cookie\"].unique().to_list()\n",
    "\n",
    "\n",
    "# Объединяем тренировочные и валидационные данные для финального обучения\n",
    "full_train_users = df_train_retriever_and_reranker[\"cookie\"]\n",
    "full_train_nodes = df_train_retriever_and_reranker[\"node\"]\n",
    "full_train_events = df_train_retriever_and_reranker[\"event\"]\n",
    "\n",
    "# Создаем веса на основе обратной частоты и контактности\n",
    "inverse_freq_weights = create_event_weights(df_train_retriever_and_reranker.select(\"event\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58b1f2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:56<00:00,  3.52s/it]\n"
     ]
    }
   ],
   "source": [
    "als_retriever = ALSRetriever(iterations=50, factors=250, regularization=0.3)\n",
    "\n",
    "als_retriever.fit(full_train_users, full_train_nodes, full_train_events, inverse_freq_weights, 100, list(inverse_freq_weights.keys()))\n",
    "\n",
    "# Получаем предсказания ALS для тестового набора\n",
    "test_als_pred = als_retriever.recommend(test_users, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d1a2ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63030/1626469783.py:66: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  .agg(pl.count().alias(\"interaction_count\"))\n",
      "/tmp/ipykernel_63030/1626469783.py:108: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  .agg(pl.count().alias(\"interaction_count\"))\n"
     ]
    }
   ],
   "source": [
    "popular_retriever = PopularItemsRetriever(df_train_retriever_and_reranker, df_cat_features)\n",
    "\n",
    "# Получаем популярные товары за последнюю неделю и месяц\n",
    "popular_week = popular_retriever.get_popular_items(days=7, top_k=200)\n",
    "popular_month = popular_retriever.get_popular_items(days=30, top_k=300)\n",
    "popular_by_category = popular_retriever.get_popular_items_by_category(days=7, top_k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbda95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_for_boosting = prepare_features_for_boosting(\n",
    "    test_als_pred,\n",
    "    df_train_retriever_and_reranker,\n",
    "    df_cat_features,\n",
    "    popular_week,\n",
    "    popular_month,\n",
    "    popular_by_category,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ef82bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (18_463_800, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>node</th><th>cookie</th><th>als_score</th><th>popular_week_count</th><th>popular_month_count</th><th>user_activity_count</th><th>category</th><th>interaction_count</th></tr><tr><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1928</td><td>1</td><td>1.42856</td><td>-1</td><td>23214</td><td>4590</td><td>13</td><td>5696</td></tr><tr><td>5744</td><td>1</td><td>1.344092</td><td>18225</td><td>74008</td><td>4590</td><td>28</td><td>18225</td></tr><tr><td>214272</td><td>1</td><td>1.309013</td><td>-1</td><td>-1</td><td>4590</td><td>37</td><td>-1</td></tr><tr><td>153004</td><td>1</td><td>1.302189</td><td>-1</td><td>25366</td><td>4590</td><td>40</td><td>-1</td></tr><tr><td>214232</td><td>1</td><td>1.228835</td><td>-1</td><td>-1</td><td>4590</td><td>37</td><td>-1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>151580</td><td>149999</td><td>0.428171</td><td>-1</td><td>-1</td><td>785</td><td>40</td><td>-1</td></tr><tr><td>51208</td><td>149999</td><td>0.427191</td><td>-1</td><td>-1</td><td>785</td><td>49</td><td>2918</td></tr><tr><td>115834</td><td>149999</td><td>0.426486</td><td>9491</td><td>38030</td><td>785</td><td>19</td><td>9491</td></tr><tr><td>149127</td><td>149999</td><td>0.426482</td><td>-1</td><td>-1</td><td>785</td><td>14</td><td>-1</td></tr><tr><td>122390</td><td>149999</td><td>0.424975</td><td>-1</td><td>-1</td><td>785</td><td>24</td><td>-1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (18_463_800, 8)\n",
       "┌────────┬────────┬───────────┬──────────────┬──────────────┬─────────────┬──────────┬─────────────┐\n",
       "│ node   ┆ cookie ┆ als_score ┆ popular_week ┆ popular_mont ┆ user_activi ┆ category ┆ interaction │\n",
       "│ ---    ┆ ---    ┆ ---       ┆ _count       ┆ h_count      ┆ ty_count    ┆ ---      ┆ _count      │\n",
       "│ i64    ┆ i64    ┆ f64       ┆ ---          ┆ ---          ┆ ---         ┆ i64      ┆ ---         │\n",
       "│        ┆        ┆           ┆ i64          ┆ i64          ┆ i64         ┆          ┆ i64         │\n",
       "╞════════╪════════╪═══════════╪══════════════╪══════════════╪═════════════╪══════════╪═════════════╡\n",
       "│ 1928   ┆ 1      ┆ 1.42856   ┆ -1           ┆ 23214        ┆ 4590        ┆ 13       ┆ 5696        │\n",
       "│ 5744   ┆ 1      ┆ 1.344092  ┆ 18225        ┆ 74008        ┆ 4590        ┆ 28       ┆ 18225       │\n",
       "│ 214272 ┆ 1      ┆ 1.309013  ┆ -1           ┆ -1           ┆ 4590        ┆ 37       ┆ -1          │\n",
       "│ 153004 ┆ 1      ┆ 1.302189  ┆ -1           ┆ 25366        ┆ 4590        ┆ 40       ┆ -1          │\n",
       "│ 214232 ┆ 1      ┆ 1.228835  ┆ -1           ┆ -1           ┆ 4590        ┆ 37       ┆ -1          │\n",
       "│ …      ┆ …      ┆ …         ┆ …            ┆ …            ┆ …           ┆ …        ┆ …           │\n",
       "│ 151580 ┆ 149999 ┆ 0.428171  ┆ -1           ┆ -1           ┆ 785         ┆ 40       ┆ -1          │\n",
       "│ 51208  ┆ 149999 ┆ 0.427191  ┆ -1           ┆ -1           ┆ 785         ┆ 49       ┆ 2918        │\n",
       "│ 115834 ┆ 149999 ┆ 0.426486  ┆ 9491         ┆ 38030        ┆ 785         ┆ 19       ┆ 9491        │\n",
       "│ 149127 ┆ 149999 ┆ 0.426482  ┆ -1           ┆ -1           ┆ 785         ┆ 14       ┆ -1          │\n",
       "│ 122390 ┆ 149999 ┆ 0.424975  ┆ -1           ┆ -1           ┆ 785         ┆ 24       ┆ -1          │\n",
       "└────────┴────────┴───────────┴──────────────┴──────────────┴─────────────┴──────────┴─────────────┘"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_for_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddc9c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_catboost = (\n",
    "    pl.DataFrame(\n",
    "        {\n",
    "            \"node\": test_data_for_boosting[\"node\"],\n",
    "            \"cookie\": test_data_for_boosting[\"cookie\"],\n",
    "            \"catboost_score\": model.predict(test_data_for_boosting.to_pandas()),\n",
    "        }\n",
    "    )\n",
    "    .sort(by=[\"cookie\", \"catboost_score\"], descending=True)\n",
    "    .group_by(\"cookie\")\n",
    "    .head(40)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fee03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_catboost[[\"cookie\", \"node\"]].write_csv(\"../data/predict/baseline_als_catboost.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5456ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df_pred_catboost[\"cookie\"].unique().to_list()) == sorted(test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48f56a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (74_771, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>cookie</th><th>node</th><th>event</th></tr><tr><td>i64</td><td>u32</td><td>i64</td></tr></thead><tbody><tr><td>116029</td><td>188671</td><td>10</td></tr><tr><td>54368</td><td>194766</td><td>4</td></tr><tr><td>103610</td><td>152470</td><td>10</td></tr><tr><td>94011</td><td>214295</td><td>10</td></tr><tr><td>31901</td><td>130860</td><td>10</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>58959</td><td>122420</td><td>10</td></tr><tr><td>117281</td><td>14048</td><td>15</td></tr><tr><td>103542</td><td>201575</td><td>4</td></tr><tr><td>5980</td><td>304053</td><td>10</td></tr><tr><td>127814</td><td>214290</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (74_771, 3)\n",
       "┌────────┬────────┬───────┐\n",
       "│ cookie ┆ node   ┆ event │\n",
       "│ ---    ┆ ---    ┆ ---   │\n",
       "│ i64    ┆ u32    ┆ i64   │\n",
       "╞════════╪════════╪═══════╡\n",
       "│ 116029 ┆ 188671 ┆ 10    │\n",
       "│ 54368  ┆ 194766 ┆ 4     │\n",
       "│ 103610 ┆ 152470 ┆ 10    │\n",
       "│ 94011  ┆ 214295 ┆ 10    │\n",
       "│ 31901  ┆ 130860 ┆ 10    │\n",
       "│ …      ┆ …      ┆ …     │\n",
       "│ 58959  ┆ 122420 ┆ 10    │\n",
       "│ 117281 ┆ 14048  ┆ 15    │\n",
       "│ 103542 ┆ 201575 ┆ 4     │\n",
       "│ 5980   ┆ 304053 ┆ 10    │\n",
       "│ 127814 ┆ 214290 ┆ 5     │\n",
       "└────────┴────────┴───────┘"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_eval_reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97c8f442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты ALS модели на тестовом наборе:\n",
      "ALS_recall@10: 0.0661\n",
      "CatBoost_recall@10: 0.0738\n",
      "ALS_recall@20: 0.1026\n",
      "CatBoost_recall@20: 0.1148\n",
      "ALS_recall@30: 0.1303\n",
      "CatBoost_recall@30: 0.1455\n",
      "ALS_recall@40: 0.1533\n",
      "CatBoost_recall@40: 0.1694\n"
     ]
    }
   ],
   "source": [
    "test_als_results = evaluate_models(\n",
    "    df_valid_eval_reranker, test_als_pred, df_pred_catboost, k_values=[10, 20, 30, 40]\n",
    ")\n",
    "print(\"\\nРезультаты ALS модели на тестовом наборе:\")\n",
    "for metric, value in test_als_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d13c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
